{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import piplite\n",
    "await piplite.install(['numpy'])\n",
    "await piplite.install(['pandas'])\n",
    "await piplite.install(['seaborn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is a software library written for the Python programming language for data manipulation and analysis.\n",
    "import pandas as pd\n",
    "# NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "import numpy as np\n",
    "# Matplotlib is a plotting library for python and pyplot gives us a MatLab like plotting framework. We will use this in our plotter function to plot data.\n",
    "import matplotlib.pyplot as plt\n",
    "#Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics\n",
    "import seaborn as sns\n",
    "# Preprocessing allows us to standarsize our data\n",
    "from sklearn import preprocessing\n",
    "# Allows us to split our data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Allows us to test parameters of classification algorithms and find the best one\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Logistic Regression classification algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Support Vector Machine classification algorithm\n",
    "from sklearn.svm import SVC\n",
    "# Decision Tree classification algorithm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# K Nearest Neighbors classification algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y,y_predict):\n",
    "    \"this function plots the confusion matrix\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    cm = confusion_matrix(y, y_predict)\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    ax.xaxis.set_ticklabels(['did not land', 'land']); ax.yaxis.set_ticklabels(['did not land', 'landed']) \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from js import fetch\n",
    "import io\n",
    "\n",
    "URL1 = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_2.csv\"\n",
    "resp1 = await fetch(URL1)\n",
    "text1 = io.BytesIO((await resp1.arrayBuffer()).to_py())\n",
    "data = pd.read_csv(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL2 = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_3.csv'\n",
    "resp2 = await fetch(URL2)\n",
    "text2 = io.BytesIO((await resp2.arrayBuffer()).to_py())\n",
    "X = pd.read_csv(text2)\n",
    "X.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Y = data['Class'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = preprocessing.StandardScaler()\n",
    "# Standardize the data\n",
    "X_standardized = transform.fit_transform(X)\n",
    "\n",
    "# Reassign the standardized data back to X\n",
    "X = pd.DataFrame(X_standardized, columns=X.columns)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters ={'C':[0.01,0.1,1],\n",
    "             'penalty':['l2'],\n",
    "             'solver':['lbfgs']}\n",
    "parameters ={\"C\":[0.01,0.1,1],'penalty':['l2'], 'solver':['lbfgs']}# l1 lasso l2 ridge\n",
    "lr=LogisticRegression()\n",
    "# Create a GridSearchCV object\n",
    "logreg_cv = GridSearchCV(estimator=lr, param_grid=parameters, cv=10)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "logreg_cv.fit(X_train, Y_train)\n",
    "\n",
    "# Output the GridSearchCV object\n",
    "print(\"GridSearchCV object:\", logreg_cv)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best parameters:\", logreg_cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from GridSearchCV\n",
    "best_model = logreg_cv.best_estimator_\n",
    "\n",
    "# Calculate the accuracy on the test data\n",
    "test_accuracy = best_model.score(X_test, Y_test)\n",
    "\n",
    "# Display the accuracy\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=logreg_cv.predict(X_test)\n",
    "plot_confusion_matrix(Y_test,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf','poly','rbf', 'sigmoid'),\n",
    "              'C': np.logspace(-3, 3, 5),\n",
    "              'gamma':np.logspace(-3, 3, 5)}\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GridSearchCV object\n",
    "svm_cv = GridSearchCV(estimator=svm, param_grid=parameters, cv=10)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "svm_cv.fit(X_train, Y_train)\n",
    "\n",
    "# Output the GridSearchCV object\n",
    "print(\"GridSearchCV object:\", svm_cv)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best parameters:\", svm_cv.best_params_)\n",
    "\n",
    "# Display the best score\n",
    "print(\"Best score:\", svm_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",svm_cv.best_params_)\n",
    "print(\"accuracy :\",svm_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from GridSearchCV\n",
    "best_svm_model = svm_cv.best_estimator_\n",
    "\n",
    "# Calculate the accuracy on the test data\n",
    "test_accuracy_svm = best_svm_model.score(X_test, Y_test)\n",
    "\n",
    "# Display the accuracy\n",
    "print(\"Test accuracy of the best SVM model:\", test_accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=svm_cv.predict(X_test)\n",
    "plot_confusion_matrix(Y_test,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a decision tree classifier object then  create a  <code>GridSearchCV</code> object  <code>tree_cv</code> with cv = 10.  Fit the object to find the best parameters from the dictionary <code>parameters</code>.\n",
    "\n",
    "parameters = {'criterion': ['gini', 'entropy'],\n",
    "     'splitter': ['best', 'random'],\n",
    "     'max_depth': [2*n for n in range(1,10)],\n",
    "     'max_features': [None, 'sqrt', 'log2'],\n",
    "     #'max_features': ['auto', 'sqrt'],\n",
    "     'min_samples_leaf': [1, 2, 4],\n",
    "     'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GridSearchCV object\n",
    "tree_cv = GridSearchCV(estimator=tree, param_grid=parameters, cv=10, error_score='raise')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "tree_cv.fit(X_train, Y_train)\n",
    "\n",
    "# Output the GridSearchCV object\n",
    "print(\"GridSearchCV object:\", tree_cv)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best parameters:\", tree_cv.best_params_)\n",
    "\n",
    "# Display the best score\n",
    "print(\"Best score:\", tree_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",tree_cv.best_params_)\n",
    "print(\"accuracy :\",tree_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the accuracy of tree_cv on the test data using the method score:\n",
    "# Get the best model from GridSearchCV\n",
    "best_tree_model = tree_cv.best_estimator_\n",
    "\n",
    "# Calculate the accuracy on the test data\n",
    "test_accuracy_tree = best_tree_model.score(X_test, Y_test)\n",
    "\n",
    "# Display the accuracy\n",
    "print(\"Test accuracy of the best Decision Tree model:\", test_accuracy_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = tree_cv.predict(X_test)\n",
    "plot_confusion_matrix(Y_test,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a k nearest neighbors object then create a GridSearchCV object knn_cv with cv = 10. Fit the object to find the best parameters from the dictionary parameters.\n",
    "parameters = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'p': [1,2]}\n",
    "\n",
    "KNN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a K-Nearest Neighbors (KNN) Classifier object\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "# Define the parameter grid for KNN\n",
    "parameters = {\n",
    "    'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "knn_cv = GridSearchCV(estimator=KNN, param_grid=parameters, cv=10)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "knn_cv.fit(X_train, Y_train)\n",
    "\n",
    "# Output the GridSearchCV object\n",
    "print(\"GridSearchCV object:\", knn_cv)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best parameters:\", knn_cv.best_params_)\n",
    "\n",
    "# Display the best score\n",
    "print(\"Best score:\", knn_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",knn_cv.best_params_)\n",
    "print(\"accuracy :\",knn_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the accuracy of knn_cv on the test data using the method score:\n",
    "# Get the best model from GridSearchCV\n",
    "best_knn_model = knn_cv.best_estimator_\n",
    "\n",
    "# Calculate the accuracy on the test data\n",
    "test_accuracy_knn = best_knn_model.score(X_test, Y_test)\n",
    "\n",
    "# Display the accuracy\n",
    "print(\"Test accuracy of the best KNN model:\", test_accuracy_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = knn_cv.predict(X_test)\n",
    "plot_confusion_matrix(Y_test,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the method performs best:\n",
    "# Assuming you've already fitted the models and calculated the test accuracies\n",
    "\n",
    "# Calculate the accuracy on the test data for each model\n",
    "test_accuracy_logreg = logreg_cv.best_estimator_.score(X_test, Y_test)\n",
    "test_accuracy_svm = svm_cv.best_estimator_.score(X_test, Y_test)\n",
    "test_accuracy_tree = tree_cv.best_estimator_.score(X_test, Y_test)\n",
    "test_accuracy_knn = knn_cv.best_estimator_.score(X_test, Y_test)\n",
    "\n",
    "# Print the test accuracies of each model\n",
    "print(\"Test accuracy of the best Logistic Regression model:\", test_accuracy_logreg)\n",
    "print(\"Test accuracy of the best SVM model:\", test_accuracy_svm)\n",
    "print(\"Test accuracy of the best Decision Tree model:\", test_accuracy_tree)\n",
    "print(\"Test accuracy of the best KNN model:\", test_accuracy_knn)\n",
    "\n",
    "# Determine the best performing model\n",
    "accuracies = {\n",
    "    'Logistic Regression': test_accuracy_logreg,\n",
    "    'SVM': test_accuracy_svm,\n",
    "    'Decision Tree': test_accuracy_tree,\n",
    "    'KNN': test_accuracy_knn\n",
    "}\n",
    "\n",
    "# Find the model with the highest accuracy\n",
    "best_model = max(accuracies, key=accuracies.get)\n",
    "best_accuracy = accuracies[best_model]\n",
    "\n",
    "print(f\"The best performing model is {best_model} with an accuracy of {best_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
